# -*- coding: utf-8 -*-
"""Submission-Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11GF0GC2T8s9eUDBNY5eOu29zginiS_LZ

**Import Library dan Packages yang Digunakan**
"""

from google.colab import drive

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""**DATA UNDERSTANDING**

**Load Data**
"""

drive.mount('/content/drive')

"""Dataset ini diambil dari platform Kaggle: https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset"""

books = pd.read_csv('/content/drive/MyDrive/Dicoding/Submission_Recommendation System/Books.csv')
ratings = pd.read_csv('/content/drive/MyDrive/Dicoding/Submission_Recommendation System/Ratings.csv')
users = pd.read_csv('/content/drive/MyDrive/Dicoding/Submission_Recommendation System/Users.csv')

print('Jumlah data "books": ', len(books.ISBN.unique()))
print('Jumlah data "ratings": ', len(ratings['User-ID'].unique()))
print('Jumlah data "users": ', len(users['User-ID'].unique()))

"""**Menampilkan Informasi Data "Books"**"""

books.head()

books.info()

"""Menunjukkan gambaran umum terkait struktur data **"Books"**. Data ini memiliki 271.360 baris data dan 8 kolom."""

# Memeriksa missing value
books.isnull().sum()

"""Terdapat *missing value* pada kolom **"Book-Author", "Publisher"**, dan **"Image-URL-L"**.

**Menampilkan Informasi Data "Ratings"**
"""

ratings.head()

ratings.info()

"""Menunjukkan gambaran umum terkait struktur data **"Ratings"**. Data ini memiliki 1.149.780  baris data dan 3 kolom."""

ratings.isnull().sum()

"""Mengecek jumlah *missing value* dari data **"Ratings"**. Dari output diatas, tidak ada *missing value* yang berarti data tersebut bersih.

**Menampilkan Informasi Data "Users"**
"""

users.head()

users.info()

"""Menunjukkan gambaran umum terkait struktur data **"Users"**. Data ini memiliki 278.858  baris data dan 3 kolom."""

users.isnull().sum()

"""Data **"Users"** memiliki *missing value* pada kolom **"Age"** sebanyak 110.762 data.

**Visualization Data**
"""

sampled_data['Year-Of-Publication'] = pd.to_numeric(sampled_data['Year-Of-Publication'], errors='coerce').fillna(0)

# Set Data type of Year-Of-Publication to Integer
sampled_data['Year-Of-Publication'] = sampled_data['Year-Of-Publication'].astype(int)

# Filter valid publication years (greater than 0)
valid_years = sampled_data[sampled_data['Year-Of-Publication'] > 0]['Year-Of-Publication']

# Count total books per year
books_per_year_filtered = valid_years.value_counts()

# Filter the number of books published above 1000
books_per_year_filtered = books_per_year_filtered[books_per_year_filtered > 1000]

# Sort data based on year of publication from the previous year
books_per_year_filtered = books_per_year_filtered.sort_index(ascending=True)

# Bar plot
plt.figure(figsize=(20, 8))
books_per_year_filtered.plot(kind='bar')
plt.title('Jumlah Buku yang Diterbitkan per Tahun (Jumlah buku diatas 1000)')
plt.xlabel('Tahun Publikasi')
plt.ylabel('Total Buku')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

"""Visualisasi diatas menunjukkan jumlah buku yang diterbitkan setiap tahunnya dari 1978-2004. Buku paling banyak diterbitkan berada pada tahun **2002**, dan paling sedikit berada pada tahun **1978**.

**DATA PREPARATION**

**Menggabungkan Data "Books", "Ratings", dan "Users"**
"""

merge_data = pd.merge(ratings, books, on='ISBN')
data = pd.merge(merge_data, users, on='User-ID')

data.head()

"""Karena data mentah terbagi menjadi 3 data yang berbeda, maka perlu menggabungkan semua data menjadi satu terlebih dahulu. Data "Ratings" dan "Books" digabungkan berdasarkan nilai **ISBN**. Kemudian, data gabungan dari ratings dan books digabungkan lagi dengan data users berdasarkan nilai **"User-ID"**. Setelah semua data sudah menjadi satu, hasilnya terlihat seperti diatas.

**Mengurangi jumlah data karena device tidak kuat melakukan running**
"""

# Mengambil sampel acak sebanyak 500.000 baris
sampled_data = data.sample(n=250000, random_state=42)

# Reset index agar indeks urut kembali setelah pengambilan sampel
sampled_data = sampled_data.reset_index(drop=True)

"""Karena banyaknya jumlah data, device tidak kuat untuk melakukan running. Oleh karena itu, dilakukan pengurangan jumlah data dan hanya menggambil 250.000 data saja.Pengambilan data tersebut dilakukan secara random.

**Menghapus kolom "Image-URL-L", "Image-URL-m" dan "Location" karena tidak digunakan dalam pembuatan sistem rekomendasi.**
"""

sampled_data.drop(columns=['Image-URL-L', 'Image-URL-M', 'Location'], inplace=True)

"""Dalam pembuatan sistem rekomendasi buku terdapat 3 kolom yang tidak akan digunakan, yaitu **"Image-URL-L", "Image-URL-m" dan "Location"**. Maka dari itu, kolomnya dihapus.

**Mengatasi Missing Value**

Mengisi nilai missing value pada data **"Books"**. Mengisi kolom "Book Author" dan "Publisher" dengan nilai modus
"""

sampled_data['Book-Author'].fillna(sampled_data['Book-Author'].mode()[0], inplace=True)
sampled_data['Publisher'].fillna(sampled_data['Publisher'].mode()[0], inplace=True)

"""**Nilai modus** adalah nilai yang paling sering muncul pada data.

Mengisi nilai missing value pada kolom **"Age"** dengan nilai median
"""

sampled_data['Age'].fillna(sampled_data['Age'].median(), inplace=True)

"""**Nilai median** adalah angka tengah dari kumpulan data yang telah diurutkan."""

sampled_data.isnull().sum()
sampled_data.head()

"""**Mengubah tipe data kolom "Age" menjadi numerik**"""

sampled_data['Age'] = pd.to_numeric(sampled_data['Age'], errors='coerce').fillna(0).astype(int)

"""Proses diatas mengkonversi data dalam kolom **"Age"** menjadi tipe data int dan mengganti nilai non-numerik menjadi 0."""

sampled_data.info()

"""Dari beberapa proses sebelumnya, terlihat bahwa semuanya telah berhasil dilakukan. Data keseluruhan berjumlah 250.000 baris dan memiliki 9 kolom data. Data ini memiliki 2 tipe data, yaitu object dan int.

Menghapus data dari kolom **"Book-Rating"** yang bernilai "0"
"""

sampled_data = sampled_data[sampled_data["Book-Rating"] != 0]

# Memeriksa rating buku yang bernilai "0"
zero_rating_books_df = sampled_data[sampled_data["Book-Rating"] == 0]
zero_rating_books_df

"""Buku yang memiliki rating 0 dihapus agar spesifikasi data yang digunakan semakin jelas, semua buku memiliki rating yang jelas."""

sampled_data.describe()

"""Tahun publikasi dan umur minimum dan maksimal tidak masuk akal.

**Mengatasi Outlier untuk data "Age" dan "Year-of-Publication**
"""

# Age
age_q1 = sampled_data['Age'].quantile(0.25)
age_q3 = sampled_data['Age'].quantile(0.75)
age_iqr = age_q3 - age_q1
age_lower_bound = age_q1 - 1.5 * age_iqr
age_upper_bound = age_q3 + 1.5 * age_iqr
sampled_data = sampled_data[(sampled_data['Age'] >= age_lower_bound) & (sampled_data['Age'] <= age_upper_bound)] # Menghapus baris yang memiliki nilai 'Age' di luar rentang [age_lower_bound, age_upper_bound]

# Year-Of-Publication
year_q1 = sampled_data['Year-Of-Publication'].quantile(0.25)
year_q3 = sampled_data['Year-Of-Publication'].quantile(0.75)
year_iqr = year_q3 - year_q1
year_lower_bound = year_q1 - 1.5 * year_iqr
year_upper_bound = year_q3 + 1.5 * year_iqr
sampled_data = sampled_data[(sampled_data['Year-Of-Publication'] >= year_lower_bound) & (sampled_data['Year-Of-Publication'] <= year_upper_bound)] # Menghapus baris yang memiliki nilai 'Tahun Terbit' di luar rentang [tahun_terbatas_bawah, tahun_terbatas_atas]

sampled_data.describe()

"""Statistik deskriptif dari data integer terlihat seperti diatas. Tahun publikasi dan umur sudah memiliki nilai yang logis."""

pd.set_option('display.max_colwidth', None)

title_sample = sampled_data[['ISBN', 'Book-Title', 'Book-Author']].sample(20)

print(title_sample.to_string(index=False))

"""Menampilkan 20 sampel baris data yang terdiri dari kolom **"ISBN", "Book-Title"**, dan **"Book-Author"**."""

data_fix = sampled_data

"""**Mendefinisikan Genre Tiap Judul Buku**

Sistem rekomendasi buku ini akan dirancang berdasarkan genre buku tersebut.
"""

genres = ['Fiction', 'Novel', 'Adventure', 'Romance', 'History', 'Thriller', 'Horror', 'Biography', 'Fantasy', 'Other']

"""Mendefinisikan genre-genre buku yang akan digunakan sebagai label untuk memprediksi genre berdasarkan judul."""

# Model Word2Vec
sentences = [title.split() for title in data_fix['Book-Title']]

# Latih model Word2Vec
model = Word2Vec(sentences, vector_size=500, window=5, min_count=5, sg=2)

"""Membuat list sentences, yang merupakan daftar kata dari setiap judul buku di kolom **"Book-Title"**. Setiap judul buku dipisahkan menjadi kata-kata."""

# Labelling

import re

def clean_text(text):
    # Menghilangkan karakter khusus dan angka
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Mengubah teks menjadi huruf kecil
    text = text.lower()
    return text

# Membuat fungsi untuk memprediksi genre dari judul buku
def predict_genre(book_title):
    clean_title = clean_text(book_title)
    title_words = clean_title.split()

    # Mengecek apakah title_words kosong
    if not title_words:
        return 'Other'

    # Memfilter kata-kata
    title_words = [word for word in title_words if word in model.wv]

    if not title_words:
        return 'Other'

    # Menghitung rata-rata vektor kata untuk judul buku
    title_vector = sum([model.wv[word] for word in title_words]) / len(title_words)

    # Menemukan genre yang paling mirip berdasarkan cosine similarity
    most_similar_genre = None
    max_similarity = -1
    for genre in genres:
        genre_vector = model.wv[genre]
        similarity = cosine_similarity([title_vector], [genre_vector])[0][0]
        if similarity > max_similarity:
            max_similarity = similarity
            most_similar_genre = genre

    return most_similar_genre

"""Secara keseluruhan, proses diatas bertujuan untuk menentukan genre buku secara otomatis berdasarkan judulnya. Model ***Word2Vec*** digunakan untuk menghasilkan representasi vektor kata, dan fungsi predict_genre mengidentifikasi genre dengan kesamaan tertinggi menggunakan metode **cosine similarity**."""

# Test
book_title_to_predict = "All Souls (Javier Marias)"
predicted_genre = predict_genre(book_title_to_predict)

print(f"The predicted genre for '{book_title_to_predict}' is {predicted_genre}.")

"""Mencoba memprediksi genre buku berdasarkan judul buku yang dimasukkan."""

!pip install swifter
import swifter

data_fix['Genre'] = data_fix['Book-Title'].swifter.apply(predict_genre)

"""Menambahkan kolom **"Genre"** ke dalam keseluruhan data, dimana data genre tersebut adalah hasil prediksi dari fungsi predict_genre sebelumnya.

**Menghapus Duplikasi Judul Buku**

Dalam membuat sistem rekomendasi, penting untuk memastikan bahwa sebuah data hanya terdapat satu, tidak ada duplikasi lain. Oleh karena itu, dilakukan proses untuk menghapus duplikasi dari data **"Book-Title"**.
"""

data_fix = data_fix.drop_duplicates(subset='Book-Title')

data_fix = data_fix.reset_index(drop=True)

data_fix.sample(10)

genre_counts = data_fix['Genre'].value_counts()

# Plotting
plt.figure(figsize=(10, 6))
genre_counts.plot(kind='bar', color='pink')
plt.title('Jumlah Buku Dari Setiap Genre')
plt.xlabel('Genre')
plt.ylabel('Jumlah Buku')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Visualisasi diatas digunakan untuk menampilkan banyaknya buku per genre. Seperti yang terlihat, buku paling banyak bergenre **horror**, dan yang paling sedikit bergenre **fantasy**.

**Mengkonversi Kolom "Book-Title" menjadi TF-IDF**
"""

# Inisialisasi TfidfVectorizer
tfidf = TfidfVectorizer()

# Mengubah kolom 'Book-Title' menjadi vektor nu merik menggunakan TF-IDF
tfidf_matrix = tfidf.fit_transform(data_fix['Book-Title'])

# Menampilkan dimensi matriks TF-IDF yang dihasilkan (baris x kolom)
tfidf_matrix.shape

"""Menggunakan teknik **TF-IDF (Term Frequency-Inverse Document Frequency)**, membuat teks dalam kolom "Book-Title" diubah menjadi representasi vektor yang akan digunakan untuk menghitung kesamaan antar buku."""

tfidf_matrix.toarray()

"""**MODELLING AND RESULT**

**Menghitung Cosine Similarity**
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity antara vektor TF-IDF untuk menemukan kesamaan antar buku
cosine_sim = cosine_similarity(tfidf_matrix)

# Menampilkan dimensi matriks cosine similarity yang dihasilkan
cosine_sim

"""Setelah vektor TF-IDF terbentuk, dilakukan perhitungan kesamaan antar judul buku menggunakan metode **cosine similarity**."""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul buku
cosine_sim_df = pd.DataFrame(cosine_sim, index=data_fix['Book-Title'], columns=data_fix['Book-Title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap judul buku
cosine_sim_df.sample(5, axis=1).sample(5, axis=0)

"""Dari proses ini, terbentuk matriks kesamaan antar judul buku dalam bentuk DataFrame dan menampilkan sampel nilai kesamaan untuk beberapa judul secara acak. Matriks kesamaan ini akan digunakan untuk sistem rekomendasi, di mana buku dengan nilai kesamaan tinggi (nilai cosine similarity yang besar) dianggap lebih relevan atau mirip satu sama lain.

**Mendapatkan Rekomendasi**
"""

def book_recommendations(judul_buku, similarity_data=cosine_sim_df, items=data_fix[['Book-Title', 'Genre']], k=5):

    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,judul_buku].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(judul_buku, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

data_fix[data_fix['Book-Title'].eq('Void Moon')]

# Mendapatkan rekomendasi buku yang mirip dengan judul buku berikut
book_recommendations('Void Moon')

"""Disini, diambil contoh buku dengan judul **"Void Moon"** dan terlihat sistem menampilkan 5 rekomendasi lain yang mirip dengan judul buku "Void Moon".

**CONCLUSION**

Kode ini berhasil mengimplementasikan sistem rekomendasi buku berdasarkan judul buku menggunakan metode vektorisasi TF-IDF pada kolom "Book-Title". Melalui perhitungan cosine similarity, sistem ini mampu merekomendasikan 5 buku yang memiliki kemiripan tinggi dengan buku yang dicari berdasarkan judul.
"""